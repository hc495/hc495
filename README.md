Working on NN/LLM Interpretability in Japan. Refer to https://www.hakaze-c.com/.

## List of Repositories

1. **Mechanism of Task-oriented Information Removal in In-context Learning** [ICLR 2026]   
   [Paper](https://arxiv.org/abs/2509.21012) [Repository](https://github.com/hc495/Verb_subspace)
2. **Binary Autoencoder for Mechanistic Interpretability of Large Language Models**   
   [Paper](https://arxiv.org/abs/2509.20997) [Repository](https://github.com/hc495/Binary_Autoencoder)
3. **Revisiting In-context Learning Inference Circuit in Large Language Models** [ICLR 2025 Poster]   
   [Paper](https://arxiv.org/abs/2410.04468) [Repository](https://github.com/hc495/ICL_Circuit) 
4. **Token-based Decision Criteria Are Suboptimal in In-context Learning** [NAACL 2025 Main]   
   [Paper](https://arxiv.org/abs/2406.16535) [Repository](https://github.com/hc495/Hidden_Calibration)  
5. **Mechanistic Fine-tuning for In-context Learning** [EMNLP 2025 BlackBox NLP workshop]   
   [Paper](https://arxiv.org/abs/2505.14233) [Repository](https://github.com/hc495/ICL_head_tuning)  
6. **Understanding Token Probability Encoding in Output Embeddings** [COLING 2025]
   [Paper](https://aclanthology.org/2025.coling-main.708/) [Repository](https://github.com/hc495/Understand_Output_Embedding) 
7. **StaICC: Standardized Toolkit for In-context Classification**
   [Paper](https://arxiv.org/abs/2501.15708) [Repository](https://github.com/hc495/StaICC) [PyPl](https://pypi.org/project/StaICC/)
8. **NoisyICL: A Little Noise in Model Parameters Calibrates In-context Learning**
   [Paper](https://arxiv.org/abs/2402.05515) [Repository](https://github.com/hc495/NoisyICL)
